{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import time\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import random\n",
    "\n",
    "path = \"/global/cscratch1/sd/ajaybati/model.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "modelasdf = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "# model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(p,r):\n",
    "    smoothie = SmoothingFunction().method2\n",
    "    bleu_list = []\n",
    "    for index in range(len(p)):\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu(p[index],r[index],smoothing_function=smoothie)\n",
    "        bleu_list.append(BLEUscore)\n",
    "    return sum(bleu_list) / len(bleu_list)\n",
    "def getSent_pred(prediction,real_labels): #convert all ids to sentences for bscore\n",
    "    sentlist_real = []\n",
    "    sep_list = []\n",
    "    for sent2 in real_labels:\n",
    "        tokenized = tokenizer.convert_ids_to_tokens(sent2)\n",
    "        sep = tokenized.index('[SEP]')\n",
    "        sep_list.append(sep)\n",
    "        sentlist_real.append(tokenized[1:sep])\n",
    "    \n",
    "    \n",
    "    sentlist_ids = []\n",
    "    sentlist = []\n",
    "    for sent in prediction:\n",
    "        word_list = []\n",
    "        for word in sent:\n",
    "            word_list.append(torch.argmax(word))\n",
    "        sentlist_ids.append(word_list)\n",
    "    \n",
    "    for index,sent in enumerate(sentlist_ids):\n",
    "        sentlist.append(tokenizer.convert_ids_to_tokens(sent)[1:sep_list[index]])\n",
    "    return sentlist,sentlist_real\n",
    "def calc_accuracy(prediction, real_labels, mask_indices):\n",
    "    score = 0\n",
    "    total = 0\n",
    "    for step,sent in enumerate(mask_indices):\n",
    "        if list(sent).count(0)!=40:\n",
    "            for mask in sent:\n",
    "                if int(mask)!=0:\n",
    "                    predicted_index = int(torch.argmax(prediction[step,int(mask)]))\n",
    "                    actual = int(real_labels[step][int(mask)])\n",
    "                    if bool(predicted_index==actual):\n",
    "                        score+=1\n",
    "                    total+=1\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    p,r = getSent_pred(prediction,real_labels)\n",
    "    \n",
    "    \n",
    "    accuracy = score/total\n",
    "    try:\n",
    "        bscore = bleu(p,r)\n",
    "    except:\n",
    "        bscore = \"Unfortunately, not possible\"\n",
    "    return accuracy, bscore \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(15.2788, grad_fn=<NllLossBackward>),\n",
       " tensor([[[ -6.7765,  -6.7445,  -6.7448,  ...,  -6.1193,  -5.9265,  -4.0404],\n",
       "          [ -5.9526,  -5.8347,  -5.8903,  ...,  -6.0357,  -6.4135,  -4.6279],\n",
       "          [-13.9339, -13.6718, -13.6458,  ..., -12.6302, -11.9930, -12.1524],\n",
       "          ...,\n",
       "          [ -8.1411,  -8.0170,  -8.2725,  ...,  -7.6747,  -7.6799,  -7.8712],\n",
       "          [ -6.8351,  -6.8551,  -6.8548,  ...,  -7.7234,  -6.6308,  -4.8302],\n",
       "          [ -7.9110,  -7.9581,  -7.6260,  ...,  -8.2757,  -6.6852,  -6.5242]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " 0.3333333333333333,\n",
       " 'Unfortunately, not possible')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bert_output(sents,n_percent_mask):\n",
    "    input_ids_real = []\n",
    "    att = []\n",
    "    compare = []\n",
    "    mask_indices = []\n",
    "    for sent in sent_tokenize(sents):\n",
    "        mask = []\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,                      # Sentence to encode.\n",
    "            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "            max_length = 64,\n",
    "            truncation = True,# Pad & truncate all sentences.\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True,   # Construct attn. masks.\n",
    "            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids = encoded_dict['input_ids']\n",
    "        compare.append(input_ids)\n",
    "        attention_masks = encoded_dict['attention_mask']\n",
    "        att.append(attention_masks)\n",
    "        input_ids_part = []\n",
    "        for step,word in enumerate(input_ids[0]):\n",
    "            if int(word) != 101 and int(word) != 102:\n",
    "                rando = random.random()\n",
    "                random.seed()\n",
    "                if rando < n_percent_mask and int(word)!=0:\n",
    "                    mask.append(step)\n",
    "                    input_ids_part.append(103)\n",
    "                else:\n",
    "                    input_ids_part.append(int(word))\n",
    "            else:\n",
    "                input_ids_part.append(int(word))\n",
    "        input_ids_part = torch.tensor(input_ids_part).view(1,64)\n",
    "        input_ids_real.append(input_ids_part)\n",
    "        mask_indices.append(mask)\n",
    "    \n",
    "    if len(input_ids_real)>1:\n",
    "        bert_input = torch.cat(tuple(input_ids_real),0)\n",
    "        att = torch.cat(tuple(att),0)\n",
    "        compare = torch.cat(tuple(compare),0)\n",
    "    else:\n",
    "        bert_input = input_ids_real[0]\n",
    "        att = att[0]\n",
    "        compare = compare[0]\n",
    "        \n",
    "    \n",
    "    loss, predictions = modelasdf(bert_input,attention_mask = att, masked_lm_labels = compare)\n",
    "    \n",
    "    accuracy, bscore = calc_accuracy(predictions, compare, mask_indices)\n",
    "    \n",
    "    \n",
    "    return loss,predictions, accuracy, bscore\n",
    "        \n",
    "\n",
    "\n",
    "yo = bert_output(\"hi, i love to eat chicken during thanksgiving feasts.\",0.2)\n",
    "yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
